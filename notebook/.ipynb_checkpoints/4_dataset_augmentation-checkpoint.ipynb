{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Auguemented Data sert\n",
    "- By exploiting the previously written code (in the trajectory generation notebook), we synthetically augment the dataset in order to have more working data.\n",
    "- We begin by loading medoids and getting/serializing graphs on disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports cell\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import osmnx as ox \n",
    "from sklearn.neighbors import KDTree\n",
    "import networkx as nx\n",
    "import folium\n",
    "import random\n",
    "from geographiclib.geodesic import Geodesic\n",
    "import math\n",
    "import yaml\n",
    "\n",
    "with open(\"conf.yaml\") as f:\n",
    "    conf = yaml.load(f, Loader = yaml.FullLoader)\n",
    "\n",
    "#base_path = conf[\"base_path\"]\n",
    "data_path = conf[\"data_path\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         lat         lon\n",
      "0  39.856215  116.640477\n",
      "1  39.652854  115.846842\n",
      "2  39.944152  116.721681\n",
      "3  39.952524  116.549498\n",
      "4  39.832093  116.079627\n",
      "We have a total of 181 starting/arrival points\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#in order to load medoids only once\n",
    "medoids = pd.read_csv(data_path + \"augmented_medoids.csv\", usecols = [\"lat\", \"lon\"])\n",
    "print(medoids.head())\n",
    "\n",
    "n_med = len(medoids)\n",
    "print(\"We have a total of {:d} starting/arrival points\".format(n_med))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We download graphs for each network type and serialize them on disk in order to save us a lot of time during the trajectory generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#get graphs from place and serialize them on disk\n",
    "\n",
    "#get the graphs\n",
    "D = ox.graph_from_place('Beijing, China', which_result=2, network_type='drive')\n",
    "B = ox.graph_from_place('Beijing, China', which_result=2, network_type='bike')\n",
    "W = ox.graph_from_place('Beijing, China', which_result=2, network_type='walk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#serialize them on disk\n",
    "ox.save_graphml(D, data_path+\"drive_graph.graphml\")\n",
    "ox.save_graphml(B, data_path+\"bike_graph.graphml\")\n",
    "ox.save_graphml(W, data_path+\"walk_graph.graphml\")\n",
    "\n",
    "print(\"Serialized graphs on disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load graphs from files if already downloaded\n",
    "\n",
    "D = ox.load_graphml(data_path+\"drive_graph.graphml\")\n",
    "B = ox.load_graphml(data_path+\"bike_graph.graphml\")\n",
    "W = ox.load_graphml(data_path+\"walk_graph.graphml\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We use the put_datetime helper function in order to put datetimes in the generated trajectories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "\n",
    "def str_time_prop(start, end, format, prop):\n",
    "    \"\"\"Get a time at a proportion of a range of two formatted times.\n",
    "\n",
    "    start and end should be strings specifying times formated in the\n",
    "    given format (strftime-style), giving an interval [start, end].\n",
    "    prop specifies how a proportion of the interval to be taken after\n",
    "    start.  The returned time will be in the specified format.\n",
    "    \"\"\"\n",
    "\n",
    "    stime = time.mktime(time.strptime(start, format))\n",
    "    etime = time.mktime(time.strptime(end, format))\n",
    "\n",
    "    ptime = stime + prop * (etime - stime)\n",
    "\n",
    "    return time.strftime(format, time.localtime(ptime))\n",
    "\n",
    "\n",
    "def random_date(start, end, prop):\n",
    "    return str_time_prop(start, end, '%Y-%m-%d %H:%M:%S', prop)\n",
    "\n",
    "#print(random_date(\"2008-06-01 00:00:00\", \"2008-08-31 23:59:00\", random.random()))\n",
    "\n",
    "def put_datetime(trajs_df, speed):\n",
    "    \n",
    "    from geopy.distance import geodesic\n",
    "    import datetime\n",
    "    from datetime import timedelta\n",
    "\n",
    "\n",
    "    traj_copy = trajs_df.copy(deep = True)\n",
    "    traj_copy[\"date_time\"] = \"2008-06-01 00:00:00\"\n",
    "\n",
    "    #selecting each traj by uid and tid\n",
    "    \n",
    "    overlaps = 0\n",
    "    index = 0\n",
    "    \n",
    "    for uid in range(traj_copy.uid.min(), traj_copy.uid.max() + 1):\n",
    "        user = traj_copy[traj_copy[\"uid\"] == uid]\n",
    "        \n",
    "        #reset intervals\n",
    "        intervals = []\n",
    "        \n",
    "        tid = user.tid.min()\n",
    "        max_tid = user.tid.max()\n",
    "        \n",
    "        \n",
    "        \n",
    "        while (tid <= max_tid):\n",
    "            \n",
    "            initial_tid_index = index\n",
    "\n",
    "            #get a random date in our range\n",
    "            date = random_date(\"2008-06-01 00:00:00\", \"2008-08-31 23:59:00\", random.random())\n",
    "            date_time_obj = datetime.datetime.strptime(date, '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "            #print(\"Trajectory {:d} starting at {:s}\".format(tid, date))\n",
    "            traj = user[user[\"tid\"] == tid]\n",
    "            #put the starting date at the beginning of the traj\n",
    "            traj_copy.iat[index, 4] = date\n",
    "            t_since_start = 0\n",
    "            d_tot = 0\n",
    "            #in order to do it only once\n",
    "            t_len = len(traj)\n",
    "\n",
    "            for i in range(1, t_len):\n",
    "                try : \n",
    "                    #print(traj.iloc[i])\n",
    "                    dist = geodesic((traj.iloc[i-1].lat, traj.iloc[i].lon), \\\n",
    "                                               (traj.iloc[i].lat, traj.iloc[i].lon))\n",
    "\n",
    "                    d_tot += dist.meters\n",
    "\n",
    "                    #gets m / m/s\n",
    "                    tdelta = (dist.meters)/speed\n",
    "                    t_since_start += tdelta\n",
    "\n",
    "                    row_dt = date_time_obj + timedelta(seconds = t_since_start)\n",
    "                    index += 1\n",
    "                    traj_copy.iat[index, 4] =  row_dt\n",
    "\n",
    "                except IndexError:\n",
    "                    print(i)\n",
    "                    #print(traj.iloc[i-1])\n",
    "                    #print(traj.iloc[i])\n",
    "                    \n",
    "            n_interval = pd.Interval(date_time_obj.timestamp(), row_dt.timestamp())\n",
    "            \n",
    "            #check if the trajectory is time-overlapping with another one\n",
    "            overlapping = False #stupid flag\n",
    "            for interval in intervals:\n",
    "                if (interval.overlaps(n_interval)):\n",
    "                    overlapping = True\n",
    "                    overlaps += 1\n",
    "                    break\n",
    "                    \n",
    "            if (overlapping):\n",
    "                index = initial_tid_index\n",
    "                continue\n",
    "                \n",
    "            else:\n",
    "                intervals.append(n_interval) \n",
    "                tid += 1\n",
    "                index += 1\n",
    "                \n",
    "            #print(\"Total time for traj n {:d}: {:f} minutes. meters: {:f}\".format(tid, t_since_start/60, d_tot))\n",
    "            #print(traj.iloc[0].date_time)\n",
    "            #print(traj.iloc[i].date_time)\n",
    "\n",
    "            #print(traj)\n",
    "    print(\"Put datetimes on {:d} rows, generated {:d} overlapping trajectories\".format(index - 1, overlaps))\n",
    "    return traj_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We define the interpolation and the faker functions to be called for each generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#interpolates the dataframe\n",
    "def interpolator(gdf, uid):\n",
    "    \n",
    "    cols = [\"lat\", \"lon\", \"uid\", \"tid\"]\n",
    "    #traj_df = pd.DataFrame(columns = cols)\n",
    "    rows = []\n",
    "    \n",
    "    #meters for interpolation\n",
    "    k = 5\n",
    "    geod = Geodesic.WGS84\n",
    "\n",
    "    for i in range(len(gdf) - 1):\n",
    "\n",
    "        l = geod.InverseLine(gdf.iloc[i].y, gdf.iloc[i].x, gdf.iloc[i+1].y, gdf.iloc[i+1].x)\n",
    "        ds = k; n = int(math.ceil(l.s13 / ds))\n",
    "        for i in range(n + 1):\n",
    "            #if i == 0:\n",
    "                #print( \"distance latitude longitude azimuth\")\n",
    "            s = min(ds * i, l.s13)\n",
    "            g = l.Position(s, Geodesic.STANDARD | Geodesic.LONG_UNROLL)\n",
    "            lat = g[\"lat2\"]\n",
    "            lon = g[\"lon2\"]\n",
    "            \n",
    "            new_row = [lat, lon, uid, 0]\n",
    "            rows.append(new_row)\n",
    "            #print(traj_df.head())\n",
    "    \n",
    "    traj_df = pd.DataFrame(rows, columns = cols)\n",
    "    \n",
    "    return traj_df\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "#faker function\n",
    "def faker(profile, n_users):\n",
    "    #traj faker helper fun\n",
    "    \n",
    "    cols = [\"lat\", \"lon\", \"uid\", \"tid\"]\n",
    "    fake_trajs = pd.DataFrame(columns = cols)\n",
    "    #uid to recognize different types of fake users\n",
    "    fake_uid = 0\n",
    "    speed = 0\n",
    "    \n",
    "    if (profile == \"drive\"):\n",
    "        G = ox.load_graphml(data_path+\"drive_graph.graphml\")\n",
    "        fake_uid = 1000\n",
    "        speed = 11.1\n",
    "        \n",
    "    elif (profile == \"bike\"):\n",
    "        G = ox.load_graphml(data_path+\"bike_graph.graphml\")\n",
    "        fake_uid = 2000\n",
    "        speed = 4.3\n",
    "\n",
    "    elif (profile == \"walk\"):\n",
    "        G = ox.load_graphml(data_path+\"walk_graph.graphml\")\n",
    "        fake_uid = 3000\n",
    "        speed = 1.38\n",
    "\n",
    "    else:\n",
    "        print(\"not a valid profile!\")\n",
    "        return None\n",
    "    \n",
    "    print(\"Loaded {:s} graph from disk\".format(profile))\n",
    "    \n",
    "    \n",
    "    gdf_nodes, gdf_edges = ox.graph_to_gdfs(G)\n",
    "    #print(gdf_nodes)\n",
    "    tree = KDTree(gdf_nodes[['y', 'x']], metric='euclidean')\n",
    "    \n",
    "    n_trajs = 0\n",
    "    errs = 0\n",
    "    trajs = []\n",
    "    \n",
    "    for i in range(0, n_users):\n",
    "        for j in range(5, random.randint(10, 15)):\n",
    "\n",
    "            #sample 2 indexes\n",
    "            picks = random.sample(range(0, n_med), 2)\n",
    "            med_a = picks[0]\n",
    "            med_b = picks[1]\n",
    "\n",
    "            #get lat and lng for medoids\n",
    "            med_a = (medoids.iloc[med_a].lat, medoids.iloc[med_a].lon)\n",
    "            med_b = (medoids.iloc[med_b].lat, medoids.iloc[med_b].lon)\n",
    "\n",
    "            #get the nearest points in the gdf\n",
    "            med_a_idx = tree.query([med_a], k=1, return_distance=False)[0]\n",
    "            med_b_idx = tree.query([med_b], k=1, return_distance=False)[0]\n",
    "\n",
    "            closest_node_to_a = gdf_nodes.iloc[med_a_idx].index.values[0]\n",
    "            closest_node_to_b = gdf_nodes.iloc[med_b_idx].index.values[0]  \n",
    "\n",
    "            #calculate the shortest path\n",
    "            try:\n",
    "                path = nx.shortest_path(G, \n",
    "                             closest_node_to_a,\n",
    "                             closest_node_to_b,\n",
    "                             weight='length')\n",
    "                n_trajs += 1\n",
    "\n",
    "            #happens when there's not path between two points    \n",
    "            except nx.NetworkXNoPath:\n",
    "                errs += 1\n",
    "                \n",
    "                \n",
    "            #print(path)\n",
    "            gdf = gdf_nodes.loc[path]\n",
    "            #print(\"Gdf number {:d}\".format(n_trajs))\n",
    "            #print(gdf.head())\n",
    "            \n",
    "            traj = interpolator(gdf, fake_uid)\n",
    "            traj[\"tid\"] = n_trajs\n",
    "            \n",
    "            trajs.append(traj)\n",
    "            #fake_trajs = fake_trajs.append(traj, ignore_index = True)\n",
    "            \n",
    "            \n",
    "            #print route for checking purposes\n",
    "            \"\"\"fig, ax = ox.plot_graph_route(G, path, fig_height=10, \n",
    "                                  fig_width=10, \n",
    "                                  show=False, close=False, \n",
    "                                  edge_color='black',\n",
    "                                  orig_dest_node_color='green',\n",
    "                                  route_color='green')\n",
    "            plt.show()\"\"\"\n",
    "            \n",
    "        #on to another user!\n",
    "        fake_uid += 1\n",
    "\n",
    "    fake_trajs = pd.concat(trajs, ignore_index = True)\n",
    "    print(\"generated {:d} trajectories for {:d} users with a {:s} profile. {:d} errors generated\"\n",
    "          .format(n_trajs, n_users, profile, errs))\n",
    "    \n",
    "    #print(fake_trajs.head())\n",
    "    \n",
    "    print(\"now putting datetimes on generated trajectories\")\n",
    "    return put_datetime(fake_trajs, speed)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We test our faker function with a relatively small generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded drive graph from disk\n",
      "generated 11 trajectories for 2 users with a drive profile. 1 errors generated\n",
      "now putting datetimes on generated trajectories\n",
      "Put datetimes on 101005 rows, generated 0 overlapping trajectories\n",
      "CPU times: user 2min 52s, sys: 5.93 s, total: 2min 58s\n",
      "Wall time: 3min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test = faker(\"drive\", 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              lat         lon   uid  tid                   date_time\n",
      "0       39.978994  116.347534  1000    1         2008-06-24 03:48:48\n",
      "1       39.978949  116.347536  1000    1  2008-06-24 03:48:48.450114\n",
      "2       39.978904  116.347538  1000    1  2008-06-24 03:48:48.900228\n",
      "3       39.978859  116.347540  1000    1  2008-06-24 03:48:49.350342\n",
      "4       39.978814  116.347543  1000    1  2008-06-24 03:48:49.800456\n",
      "...           ...         ...   ...  ...                         ...\n",
      "101001  39.834279  116.602001  1001   11  2008-06-29 11:41:21.179171\n",
      "101002  39.834324  116.602002  1001   11  2008-06-29 11:41:21.629614\n",
      "101003  39.834369  116.602002  1001   11  2008-06-29 11:41:22.080058\n",
      "101004  39.834414  116.602002  1001   11  2008-06-29 11:41:22.530501\n",
      "101005  39.834452  116.602003  1001   11  2008-06-29 11:41:22.911635\n",
      "\n",
      "[101006 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "print(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Having succeeded in running our faker function, we proceed to the true dataset augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now starting generation with 70 cars, 30 bikes and 100 pedestrians\n",
      "Loaded drive graph from disk\n",
      "generated 516 trajectories for 70 users with a drive profile. 9 errors generated\n",
      "now putting datetimes on generated trajectories\n",
      "Put datetimes on 3890916 rows, generated 0 overlapping trajectories\n",
      "Loaded bike graph from disk\n",
      "generated 219 trajectories for 30 users with a bike profile. 1 errors generated\n",
      "now putting datetimes on generated trajectories\n",
      "Put datetimes on 1602609 rows, generated 1 overlapping trajectories\n",
      "Loaded walk graph from disk\n",
      "generated 778 trajectories for 100 users with a walk profile. 0 errors generated\n",
      "now putting datetimes on generated trajectories\n",
      "Put datetimes on 5810613 rows, generated 10 overlapping trajectories\n",
      "CPU times: user 4h 42min 54s, sys: 6min 3s, total: 4h 48min 58s\n",
      "Wall time: 5h 3min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "num_cars = conf[\"cars\"]\n",
    "num_bikes = conf[\"bikes\"]\n",
    "num_pedestrians = conf[\"pedestrians\"]\n",
    "\n",
    "print(\"Now starting generation with {:d} cars, {:d} bikes and {:d} pedestrians\"\n",
    "     .format(num_cars, num_bikes, num_pedestrians))\n",
    "\n",
    "cars = faker(\"drive\", num_cars)\n",
    "bikes = faker(\"bike\", num_bikes)\n",
    "pedestrians = faker(\"walk\", num_pedestrians)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 51s, sys: 4.35 s, total: 1min 55s\n",
      "Wall time: 2min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cars.to_csv(data_path+\"augmented_cars.csv\")\n",
    "bikes.to_csv(data_path+\"augmented_bikes.csv\")\n",
    "pedestrians.to_csv(data_path+\"augmented_pedestrians.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               lat         lon   uid  tid                   date_time\n",
      "0        40.087859  116.294835  2000    1         2008-06-29 19:13:11\n",
      "1        40.087820  116.294864  2000    1  2008-06-29 19:13:12.008406\n",
      "2        40.087781  116.294893  2000    1  2008-06-29 19:13:13.016812\n",
      "3        40.087742  116.294922  2000    1  2008-06-29 19:13:14.025218\n",
      "4        40.087702  116.294952  2000    1  2008-06-29 19:13:15.033625\n",
      "...            ...         ...   ...  ...                         ...\n",
      "3179726  39.701495  116.719977  2049  389  2008-08-24 22:16:21.741904\n",
      "3179727  39.701479  116.719922  2049  389  2008-08-24 22:16:22.154408\n",
      "3179728  39.701463  116.719868  2049  389  2008-08-24 22:16:22.566914\n",
      "3179729  39.701448  116.719813  2049  389  2008-08-24 22:16:22.979420\n",
      "3179730  39.701439  116.719784  2049  389  2008-08-24 22:16:23.196714\n",
      "\n",
      "[3179731 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "print(bikes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if the trajectory generation worked correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trajs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-6e8c1558a397>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#print(trajs)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mtdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mskmob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrajDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrajs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrajs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"uid\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlongitude\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"lon\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdatetime\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"date_time\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'trajs' is not defined"
     ]
    }
   ],
   "source": [
    "import skmob\n",
    "\n",
    "#print(trajs)\n",
    "\n",
    "tdf = skmob.TrajDataFrame(trajs[(trajs[\"uid\"] == 1000)], longitude = \"lon\", datetime = \"date_time\")\n",
    "print(tdf)\n",
    "\n",
    "\n",
    "tdf.plot_trajectory(zoom=12, weight=3, opacity=0.9, tiles='Stamen Toner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We put everything together and serialize the resulting complete dataset on disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   date_time        lat         lon   tid  uid\n",
      "2101262  2008-06-17 09:44:44  39.976060  116.310953  1440   10\n",
      "2101263  2008-06-17 09:44:45  39.976016  116.310973  1440   10\n",
      "2101264  2008-06-17 09:44:46  39.975973  116.311003  1440   10\n",
      "2101265  2008-06-17 09:44:47  39.975938  116.311025  1440   10\n",
      "2101266  2008-06-17 09:44:48  39.975906  116.311038  1440   10\n",
      "18592\n"
     ]
    }
   ],
   "source": [
    "col_names = [\"lat\", \"lon\", \"uid\", \"tid\", \"date_time\"] \n",
    "\n",
    "pedestrians = pd.read_csv(data_path + \"augmented_pedestrians.csv\", parse_dates = True, infer_datetime_format = True\n",
    "                        ,index_col = 0)\n",
    "bikes = pd.read_csv(data_path + \"augmented_bikes.csv\", parse_dates = True, infer_datetime_format = True\n",
    "                        ,index_col = 0)\n",
    "cars = pd.read_csv(data_path + \"augmented_cars.csv\", parse_dates = True, infer_datetime_format = True\n",
    "                        ,index_col = 0)\n",
    "\n",
    "cols = [\"date_time\", \"lat\", \"lon\", \"tid\", \"uid\"]\n",
    "\n",
    "df = pd.read_csv(data_path + \"complete_with_tids.csv\", \\\n",
    "                 usecols = cols, parse_dates = True, infer_datetime_format = True)\n",
    "#restricting to beijing area\n",
    "df = df[(df['lat'].between(39.54, 40.3)) & (df['lon'].between(115.75, 117.13))]\n",
    "\n",
    "#restricting to june - august 2008\n",
    "start_time = \"2008-06-01 00:00:00\"\n",
    "end_time = \"2008-08-31 23:59:00\"\n",
    "\n",
    "original = (df[(df.date_time > start_time) & (df.date_time < end_time)]).copy()\n",
    "\n",
    "print(original.head())\n",
    "print(original.tid.max())\n",
    "\n",
    "#augmented[\"date_time\"] = pd.to_datetime(augmented[\"date_time\"], format = \"%Y-%m-%d %H:%M:%S.%f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pedestrians[\"tid\"] += original.tid.max()\n",
    "bikes[\"tid\"] += (original.tid.max() + pedestrians.tid.max())\n",
    "cars[\"tid\"] += (original.tid.max() + pedestrians.tid.max() + bikes.tid.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented = pd.concat([pedestrians, bikes, cars, original], axis=0, ignore_index=True)\n",
    "augmented.to_csv(data_path + \"augmented_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:skmob]",
   "language": "python",
   "name": "skmob"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
