{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different coverage scenarios\n",
    "In this notebook we analyze various scenarios regarding different kinds of sensing i.e. environmental monitoring, traffic fluxes and  POI-based sensing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded trajectory dataset\n"
     ]
    }
   ],
   "source": [
    "#we set up all the functions we need and load up some datasets.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import yaml\n",
    "\n",
    "with open(\"conf.yaml\") as f:\n",
    "    conf = yaml.load(f, Loader = yaml.FullLoader)\n",
    "\n",
    "base_path = conf[\"base_path\"]\n",
    "data_path = conf[\"data_path\"]\n",
    "out_path = conf[\"out_path\"]\n",
    "\n",
    "cols = [\"lat\", \"lon\", \"uid\", \"tid\",\"date_time\"]\n",
    "\n",
    "# Define a basic Haversine distance formula\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    \n",
    "    lat1, lon1, lat2, lon2 = map(np.deg2rad, [lat1, lon1, lat2, lon2])\n",
    "    dlat = lat2 - lat1 \n",
    "    dlon = lon2 - lon1 \n",
    "    a = np.sin(dlat/2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2\n",
    "    c = 2 * np.arcsin(np.sqrt(a)) \n",
    "    #total_meters = METERS * c\n",
    "    r = 6371000 #radiu * 1000 to return meters\n",
    "    return c * r\n",
    "\n",
    "import scipy.integrate as integrate\n",
    "\n",
    "def coverage(loc_array, tot_dists_df, lam, delta):\n",
    "    coverage = pd.DataFrame()\n",
    "    coverage[\"location\"] = loc_array\n",
    "    coverage[\"probability\"] = calculate_coverage(loc_array, tot_dists_df, lam, delta)\n",
    "    return coverage\n",
    "\n",
    "def calculate_coverage(locations, tot_dists_df, lam, delta):\n",
    "    \n",
    "    lenght = len(locations)\n",
    "    count = 0\n",
    "    coverages = []\n",
    "    \n",
    "    #initialize coverage inner function\n",
    "    lam = lam\n",
    "    delta = delta\n",
    "    inner = lambda x: lam * (1/( (np.e)**(lam*x) ))\n",
    "    integral = lambda x: 1 - integrate.quad(inner, x, x+delta)[0]\n",
    "    vec_integral = np.vectorize(integral)\n",
    "    print(\"Calculating coverage with lambda set to: {:4f} and delta set to: {:f}\".format(lam, delta))\n",
    "    \n",
    "    for loc in locations:\n",
    "        \n",
    "        #if the location has no points whatsoever, assign 0 to the probability and continue\n",
    "        if(tot_dists_df[tot_dists_df.location == loc].uid.isnull().values.any()):\n",
    "            coverages.append(0)\n",
    "            count += 1\n",
    "            print(\"Computed coverage on {:d} out of {:d} locations, with lambda set to {:f}\".format(count, lenght, lam), end=\"\\r\")\n",
    "            continue\n",
    "        \n",
    "        tot_dists_location = tot_dists_df[tot_dists_df.location == loc]\n",
    "        uids = tot_dists_location.uid.unique()\n",
    "        #print(uids)\n",
    "        user_probs = []\n",
    "\n",
    "        for user in uids:\n",
    "            #print(user)\n",
    "            tot_dists_user = tot_dists_location[(tot_dists_location.uid == user)]\n",
    "            \n",
    "            #print(tot_dists_user)\n",
    "            inner_vals = vec_integral(tot_dists_user.distance.values)\n",
    "            prob = 1 - np.prod(inner_vals)\n",
    "            user_probs.append(prob)\n",
    "\n",
    "        location_coverage = 1 - np.prod(user_probs)\n",
    "        coverages.append(location_coverage)\n",
    "        count += 1\n",
    "        print(\"Computed coverage on {:d} out of {:d} locations, with lambda set to {:f}\".format(count, lenght, lam), end=\"\\r\")\n",
    "        \n",
    "    return coverages\n",
    "\n",
    "#calculates coverages on multiple lambda values and serializes them on disk\n",
    "def coverage_multiple_lambdas(lambdas, delta, locations, tot_dists_df, prefix):\n",
    "    for value in lambdas:\n",
    "        lam = value\n",
    "        coverages = coverage(locations, tot_dists_df, lam, delta)\n",
    "        #merge with df_t dataframe with location positions on \"location\" id then serialize on disk\n",
    "        merged = df.merge(coverages, on=\"location\")\n",
    "        name = prefix + \"_coverages_\" + str(value).replace(\".\", \",\") + \"_lambda.csv\"\n",
    "        merged.to_csv(data_path + name)\n",
    "        \n",
    "\n",
    "dataset = pd.read_csv(data_path + \"augmented_dataset.csv\", usecols=cols, parse_dates = True)\n",
    "print(\"Successfully loaded trajectory dataset\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load up lambda values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01, 0.0033333333333333335, 0.002]\n"
     ]
    }
   ],
   "source": [
    "#used to parse the conf lambdas\n",
    "def convert(s):\n",
    "    try:\n",
    "        return float(s)\n",
    "    except ValueError:\n",
    "        num, denom = s.split('/')\n",
    "        return float(num) / float(denom)\n",
    "\n",
    "lambdas = (list(map(convert, conf[\"lambdas\"])))\n",
    "\n",
    "print(lambdas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traffic fluxes sensing\n",
    "We load up a csv comprising all of Beijing's subway stations subsequently computing coverage on it after filtering our locations according to a certain detour radius."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 312 entries, 0 to 311\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   name    312 non-null    object \n",
      " 1   lat     312 non-null    float64\n",
      " 2   lon     312 non-null    float64\n",
      "dtypes: float64(2), object(1)\n",
      "memory usage: 7.4+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#We load up the dataset\n",
    "df = pd.read_csv(base_path + \"/beijing_subway_stations.csv\")\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 10 locations that have no points in detour radius' range\n",
      "312  - Unique sensing locations\n"
     ]
    }
   ],
   "source": [
    "#restricting according to detour radius\n",
    "#for each user, for each trajectory of the user, get the distance of all its waypoints that are in our detour radius' range\n",
    "\n",
    "detour_radius = conf[\"detour_radius\"] #meters\n",
    "dists = []\n",
    "count = 0\n",
    "\n",
    "for location in df.index.values:\n",
    "    d_i_h = pd.DataFrame()\n",
    "    d_i_h[\"distance\"] = haversine(df.loc[location].lat, df.loc[location].lon, dataset[\"lat\"].values, dataset[\"lon\"].values)\n",
    "    d_i_h = d_i_h[d_i_h.distance < detour_radius]\n",
    "    if (len(d_i_h) > 0):\n",
    "        d_i_h[\"uid\"] = dataset[\"uid\"]\n",
    "        d_i_h[\"location\"] = location\n",
    "    else:\n",
    "        d_i_h = pd.DataFrame({\"location\":location, \"uid\":np.nan, \"distance\":np.nan}, index=[0])\n",
    "        count += 1\n",
    "        #print(d_i_h)\n",
    "    dists.append(d_i_h)\n",
    "    \n",
    "print(\"There are {:d} locations that have no points in detour radius' range\".format(count)) \n",
    "\n",
    "subway_dists = pd.concat(dists)\n",
    "print(len(subway_dists.location.unique()), \" - Unique sensing locations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     name        lat         lon  location\n",
      "0      西四  39.922554  116.366718         0\n",
      "1      高井  39.947944  116.152161         1\n",
      "2     金台路  39.921706  116.472480         2\n",
      "3      枣营  39.942932  116.469014         3\n",
      "4    朝阳公园  39.931925  116.472418         4\n",
      "..    ...        ...         ...       ...\n",
      "307  六道口站  39.999398  116.347699       307\n",
      "308   首经贸  39.843178  116.314072       308\n",
      "309   高楼金  39.861837  116.679565       309\n",
      "310    群芳  39.862322  116.664681       310\n",
      "311   万盛东  39.862333  116.650963       311\n",
      "\n",
      "[312 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "#print(tot_dists.location.unique())\n",
    "locations = subway_dists.location.unique()\n",
    "df[\"location\"] = locations\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traffic fluxes - coverage probability\n",
    "Now we compute coverage on the locations according to our model serialize resulting csvs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We're about to calculate coverage with the following lambdas:  [0.01, 0.0033333333333333335, 0.002]\n",
      "Calculating coverage with lambda set to: 0.010000 and delta set to: 10.000000\n",
      "Calculating coverage with lambda set to: 0.003333 and delta set to: 10.000000\n",
      "Calculating coverage with lambda set to: 0.002000 and delta set to: 10.000000\n",
      "Computed coverage on 52 out of 312 locations, with lambda set to 0.002000\r"
     ]
    }
   ],
   "source": [
    "#print(lambdas)\n",
    "\n",
    "delta = conf[\"delta\"]\n",
    "prefix = \"subway\" #used to get a meeaningful name for out .csv\n",
    "\n",
    "print(\"We're about to calculate coverage with the following lambdas: \", lambdas)\n",
    "\n",
    "coverage_multiple_lambdas(lambdas, delta, locations, subway_dists, prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:skmob]",
   "language": "python",
   "name": "skmob"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
