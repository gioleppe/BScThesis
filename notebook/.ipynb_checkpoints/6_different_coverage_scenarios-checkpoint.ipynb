{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different coverage scenarios\n",
    "In this notebook we analyze various scenarios regarding different kinds of sensing i.e. environmental monitoring, traffic fluxes and  POI-based sensing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded trajectory dataset\n"
     ]
    }
   ],
   "source": [
    "#we set up all the functions we need and load up some datasets.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import yaml\n",
    "\n",
    "with open(\"conf.yaml\") as f:\n",
    "    conf = yaml.load(f, Loader = yaml.FullLoader)\n",
    "\n",
    "base_path = conf[\"base_path\"]\n",
    "data_path = conf[\"data_path\"]\n",
    "out_path = conf[\"out_path\"]\n",
    "\n",
    "cols = [\"lat\", \"lon\", \"uid\", \"tid\",\"date_time\"]\n",
    "\n",
    "# Define a basic Haversine distance formula\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    \n",
    "    lat1, lon1, lat2, lon2 = map(np.deg2rad, [lat1, lon1, lat2, lon2])\n",
    "    dlat = lat2 - lat1 \n",
    "    dlon = lon2 - lon1 \n",
    "    a = np.sin(dlat/2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2\n",
    "    c = 2 * np.arcsin(np.sqrt(a)) \n",
    "    #total_meters = METERS * c\n",
    "    r = 6371000 #radiu * 1000 to return meters\n",
    "    return c * r\n",
    "\n",
    "import scipy.integrate as integrate\n",
    "\n",
    "def coverage(loc_array, tot_dists_df, lam, delta):\n",
    "    coverage = pd.DataFrame()\n",
    "    coverage[\"location\"] = loc_array\n",
    "    coverage[\"probability\"] = calculate_coverage(loc_array, tot_dists_df, lam, delta)\n",
    "    return coverage\n",
    "\n",
    "def calculate_coverage(locations, tot_dists_df, lam, delta):\n",
    "    \n",
    "    lenght = len(locations)\n",
    "    count = 0\n",
    "    coverages = []\n",
    "    \n",
    "    #initialize coverage inner function\n",
    "    lam = lam\n",
    "    delta = delta\n",
    "    inner = lambda x: lam * (1/( (np.e)**(lam*x) ))\n",
    "    integral = lambda x: 1 - integrate.quad(inner, x, x+delta)[0]\n",
    "    vec_integral = np.vectorize(integral)\n",
    "    print(\"Calculating coverage with lambda set to: {:4f} and delta set to: {:f}\".format(lam, delta))\n",
    "    \n",
    "    for loc in locations:\n",
    "        \n",
    "        #if the location has no points whatsoever, assign 0 to the probability and continue\n",
    "        if(tot_dists_df[tot_dists_df.location == loc].uid.isnull().values.any()):\n",
    "            coverages.append(0)\n",
    "            count += 1\n",
    "            print(\"Computed coverage on {:d} out of {:d} locations, with lambda set to {:f}\".format(count, lenght, lam), end=\"\\r\")\n",
    "            continue\n",
    "        \n",
    "        tot_dists_location = tot_dists_df[tot_dists_df.location == loc]\n",
    "        uids = tot_dists_location.uid.unique()\n",
    "        #print(uids)\n",
    "        user_probs = []\n",
    "\n",
    "        for user in uids:\n",
    "            #print(user)\n",
    "            tot_dists_user = tot_dists_location[(tot_dists_location.uid == user)]\n",
    "            \n",
    "            #print(tot_dists_user)\n",
    "            inner_vals = vec_integral(tot_dists_user.distance.values)\n",
    "            prob = 1 - np.prod(inner_vals)\n",
    "            user_probs.append(prob)\n",
    "\n",
    "        location_coverage = 1 - np.prod(user_probs)\n",
    "        coverages.append(location_coverage)\n",
    "        count += 1\n",
    "        print(\"Computed coverage on {:d} out of {:d} locations, with lambda set to {:f}\".format(count, lenght, lam), end=\"\\r\")\n",
    "        \n",
    "    return coverages\n",
    "\n",
    "#calculates coverages on multiple lambda values and serializes them on disk\n",
    "def coverage_multiple_lambdas(lambdas, delta, locations, tot_dists_df, prefix):\n",
    "    for value in lambdas:\n",
    "        lam = value\n",
    "        coverages = coverage(locations, tot_dists_df, lam, delta)\n",
    "        #merge with df_t dataframe with location positions on \"location\" id then serialize on disk\n",
    "        merged = df.merge(coverages, on=\"location\")\n",
    "        name = prefix + \"_coverages_\" + str(value).replace(\".\", \",\") + \"_lambda.csv\"\n",
    "        merged.to_csv(data_path + name)\n",
    "        \n",
    "\n",
    "dataset = pd.read_csv(data_path + \"augmented_dataset.csv\", usecols=cols, parse_dates = True)\n",
    "print(\"Successfully loaded trajectory dataset\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load up lambda values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01, 0.00333333, 0.00142857]\n"
     ]
    }
   ],
   "source": [
    "#used to parse the conf lambdas\n",
    "def convert(s):\n",
    "    try:\n",
    "        return float(s)\n",
    "    except ValueError:\n",
    "        num, denom = s.split('/')\n",
    "        return float(num) / float(denom)\n",
    "\n",
    "lambdas = (list(map(convert, conf[\"lambdas\"])))\n",
    "\n",
    "print(lambdas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traffic fluxes sensing\n",
    "We load up a csv comprising all of Beijing's subway stations subsequently computing coverage on it after filtering our locations according to a certain detour radius."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 312 entries, 0 to 311\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   name    312 non-null    object \n",
      " 1   lat     312 non-null    float64\n",
      " 2   lon     312 non-null    float64\n",
      "dtypes: float64(2), object(1)\n",
      "memory usage: 7.4+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#We load up the dataset\n",
    "df = pd.read_csv(data_path + \"beijing_subway_stations.csv\")\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 10 locations that have no points in detour radius' range\n",
      "312  - Unique sensing locations\n"
     ]
    }
   ],
   "source": [
    "#restricting according to detour radius\n",
    "#for each user, for each trajectory of the user, get the distance of all its waypoints that are in our detour radius' range\n",
    "\n",
    "detour_radius = conf[\"detour_radius\"] #meters\n",
    "dists = []\n",
    "count = 0\n",
    "\n",
    "for location in df.index.values:\n",
    "    d_i_h = pd.DataFrame()\n",
    "    d_i_h[\"distance\"] = haversine(df.loc[location].lat, df.loc[location].lon, dataset[\"lat\"].values, dataset[\"lon\"].values)\n",
    "    d_i_h = d_i_h[d_i_h.distance < detour_radius]\n",
    "    if (len(d_i_h) > 0):\n",
    "        d_i_h[\"uid\"] = dataset[\"uid\"]\n",
    "        d_i_h[\"location\"] = location\n",
    "    else:\n",
    "        d_i_h = pd.DataFrame({\"location\":location, \"uid\":np.nan, \"distance\":np.nan}, index=[0])\n",
    "        count += 1\n",
    "        #print(d_i_h)\n",
    "    dists.append(d_i_h)\n",
    "    \n",
    "print(\"There are {:d} locations that have no points in detour radius' range\".format(count)) \n",
    "\n",
    "subway_dists = pd.concat(dists)\n",
    "print(len(subway_dists.location.unique()), \" - Unique sensing locations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     name        lat         lon  location\n",
      "0      西四  39.922554  116.366718         0\n",
      "1      高井  39.947944  116.152161         1\n",
      "2     金台路  39.921706  116.472480         2\n",
      "3      枣营  39.942932  116.469014         3\n",
      "4    朝阳公园  39.931925  116.472418         4\n",
      "..    ...        ...         ...       ...\n",
      "307  六道口站  39.999398  116.347699       307\n",
      "308   首经贸  39.843178  116.314072       308\n",
      "309   高楼金  39.861837  116.679565       309\n",
      "310    群芳  39.862322  116.664681       310\n",
      "311   万盛东  39.862333  116.650963       311\n",
      "\n",
      "[312 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "#print(tot_dists.location.unique())\n",
    "locations = subway_dists.location.unique()\n",
    "df[\"location\"] = locations\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traffic fluxes - coverage probability\n",
    "Now we compute coverage on the locations according to our model serialize resulting csvs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We're about to calculate coverage with the following lambdas:  [0.01, 0.00333333, 0.00142857]\n",
      "Calculating coverage with lambda set to: 0.010000 and delta set to: 10.000000\n",
      "Calculating coverage with lambda set to: 0.003333 and delta set to: 10.000000\n",
      "Calculating coverage with lambda set to: 0.001429 and delta set to: 10.000000\n",
      "Computed coverage on 312 out of 312 locations, with lambda set to 0.001429\r"
     ]
    }
   ],
   "source": [
    "#print(lambdas)\n",
    "\n",
    "delta = conf[\"delta\"]\n",
    "prefix = \"subway\" #used to get a meeaningful name for out .csv\n",
    "\n",
    "print(\"We're about to calculate coverage with the following lambdas: \", lambdas)\n",
    "\n",
    "coverage_multiple_lambdas(lambdas, delta, locations, subway_dists, prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POI-based sensing\n",
    "We load up a csv with landmarks and similar POIs in order to compute coverage on it, for a sensing based on a wider range of locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 956 entries, 0 to 955\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Unnamed: 0  956 non-null    int64  \n",
      " 1   name        797 non-null    object \n",
      " 2   name:en     533 non-null    object \n",
      " 3   lat         956 non-null    float64\n",
      " 4   lon         956 non-null    float64\n",
      "dtypes: float64(2), int64(1), object(2)\n",
      "memory usage: 37.5+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#We load up the dataset\n",
    "df = pd.read_csv(data_path + \"POIs.csv\")\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 64 locations that have no points in detour radius' range\n",
      "956  - Unique sensing locations\n"
     ]
    }
   ],
   "source": [
    "#restricting according to detour radius\n",
    "#for each user, for each trajectory of the user, get the distance of all its waypoints that are in our detour radius' range\n",
    "\n",
    "detour_radius = conf[\"detour_radius\"] #meters\n",
    "dists = []\n",
    "count = 0\n",
    "\n",
    "for location in df.index.values:\n",
    "    d_i_h = pd.DataFrame()\n",
    "    d_i_h[\"distance\"] = haversine(df.loc[location].lat, df.loc[location].lon, dataset[\"lat\"].values, dataset[\"lon\"].values)\n",
    "    d_i_h = d_i_h[d_i_h.distance < detour_radius]\n",
    "    if (len(d_i_h) > 0):\n",
    "        d_i_h[\"uid\"] = dataset[\"uid\"]\n",
    "        d_i_h[\"location\"] = location\n",
    "    else:\n",
    "        d_i_h = pd.DataFrame({\"location\":location, \"uid\":np.nan, \"distance\":np.nan}, index=[0])\n",
    "        count += 1\n",
    "        #print(d_i_h)\n",
    "    dists.append(d_i_h)\n",
    "    \n",
    "print(\"There are {:d} locations that have no points in detour radius' range\".format(count)) \n",
    "\n",
    "POIs_dists = pd.concat(dists)\n",
    "print(len(POIs_dists.location.unique()), \" - Unique sensing locations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Unnamed: 0     name                          name:en        lat  \\\n",
      "0             0      北京东                     Beijing East  39.901209   \n",
      "1             1       丰台                          Fengtai  39.846962   \n",
      "2             2       北京                          Beijing  39.902166   \n",
      "3             3       良乡                       Liangxiang  39.740095   \n",
      "4             4       永乐                           Yongle  39.651827   \n",
      "..          ...      ...                              ...        ...   \n",
      "951         951     世纪之园                              NaN  39.730442   \n",
      "952         952    天安门广场                Tian'anmen Square  39.902361   \n",
      "953         953     恒基中心                 Henderson Center  39.905265   \n",
      "954         954  人民英雄纪念碑  Monument to the People's Heroes  39.903195   \n",
      "955         955   六佰本商业街                              NaN  40.007395   \n",
      "\n",
      "            lon  location  \n",
      "0    116.478643         0  \n",
      "1    116.282636         1  \n",
      "2    116.421012         2  \n",
      "3    116.151421         3  \n",
      "4    116.790273         4  \n",
      "..          ...       ...  \n",
      "951  116.112839       951  \n",
      "952  116.391460       952  \n",
      "953  116.422047       953  \n",
      "954  116.391431       954  \n",
      "955  116.460662       955  \n",
      "\n",
      "[956 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "#print(tot_dists.location.unique())\n",
    "locations = POIs_dists.location.unique()\n",
    "df[\"location\"] = locations\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POIs - coverage probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We're about to calculate coverage with the following lambdas:  [0.01, 0.00333333, 0.00142857]\n",
      "Calculating coverage with lambda set to: 0.010000 and delta set to: 10.000000\n",
      "Calculating coverage with lambda set to: 0.003333 and delta set to: 10.000000\n",
      "Calculating coverage with lambda set to: 0.001429 and delta set to: 10.000000\n",
      "Computed coverage on 956 out of 956 locations, with lambda set to 0.001429\r"
     ]
    }
   ],
   "source": [
    "#print(lambdas)\n",
    "\n",
    "delta = conf[\"delta\"]\n",
    "prefix = \"POIs\" #used to get a meeaningful name for out .csv\n",
    "\n",
    "print(\"We're about to calculate coverage with the following lambdas: \", lambdas)\n",
    "\n",
    "coverage_multiple_lambdas(lambdas, delta, locations, POIs_dists, prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid-based environmental sensing\n",
    "We load up a previously generated regular grid in order to simulate an environmental type of sensing, (e.g. environmental values such as temperature, pressure etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 204 entries, 0 to 203\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Unnamed: 0  204 non-null    int64  \n",
      " 1   lon         204 non-null    float64\n",
      " 2   lat         204 non-null    float64\n",
      " 3   location    204 non-null    int64  \n",
      "dtypes: float64(2), int64(2)\n",
      "memory usage: 6.5 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#We load up the grid dataset\n",
    "df = pd.read_csv(data_path + \"5000_m_grid.csv\")\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 69 locations that have no points in detour radius' range\n",
      "204  - Unique sensing locations\n"
     ]
    }
   ],
   "source": [
    "#restricting according to detour radius\n",
    "#for each user, for each trajectory of the user, get the distance of all its waypoints that are in our detour radius' range\n",
    "\n",
    "detour_radius = conf[\"detour_radius\"] #meters\n",
    "dists = []\n",
    "count = 0\n",
    "\n",
    "for location in df.index.values:\n",
    "    d_i_h = pd.DataFrame()\n",
    "    d_i_h[\"distance\"] = haversine(df.loc[location].lat, df.loc[location].lon, dataset[\"lat\"].values, dataset[\"lon\"].values)\n",
    "    d_i_h = d_i_h[d_i_h.distance < detour_radius]\n",
    "    if (len(d_i_h) > 0):\n",
    "        d_i_h[\"uid\"] = dataset[\"uid\"]\n",
    "        d_i_h[\"location\"] = location\n",
    "    else:\n",
    "        d_i_h = pd.DataFrame({\"location\":location, \"uid\":np.nan, \"distance\":np.nan}, index=[0])\n",
    "        count += 1\n",
    "        #print(d_i_h)\n",
    "    dists.append(d_i_h)\n",
    "    \n",
    "print(\"There are {:d} locations that have no points in detour radius' range\".format(count)) \n",
    "\n",
    "grid_dists = pd.concat(dists)\n",
    "print(len(grid_dists.location.unique()), \" - Unique sensing locations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Unnamed: 0         lon        lat  location\n",
      "0             0  115.765700  39.633200         0\n",
      "1             1  115.765700  39.678581         1\n",
      "2             2  115.765700  39.723932         2\n",
      "3             3  115.765700  39.769253         3\n",
      "4             4  115.765700  39.814545         4\n",
      "..          ...         ...        ...       ...\n",
      "199         199  116.708813  39.950240       199\n",
      "200         200  116.708813  39.995412       200\n",
      "201         201  116.708813  40.040555       201\n",
      "202         202  116.708813  40.085667       202\n",
      "203         203  116.708813  40.130750       203\n",
      "\n",
      "[204 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "#print(tot_dists.location.unique())\n",
    "locations = grid_dists.location.unique()\n",
    "df[\"location\"] = locations\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid - coverage probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We're about to calculate coverage with the following lambdas:  [0.01, 0.00333333, 0.00142857]\n",
      "Calculating coverage with lambda set to: 0.010000 and delta set to: 10.000000\n",
      "Calculating coverage with lambda set to: 0.003333 and delta set to: 10.000000\n",
      "Calculating coverage with lambda set to: 0.001429 and delta set to: 10.000000\n",
      "Computed coverage on 204 out of 204 locations, with lambda set to 0.001429\r"
     ]
    }
   ],
   "source": [
    "#print(lambdas)\n",
    "\n",
    "delta = conf[\"delta\"]\n",
    "prefix = \"grid\" #used to get a meeaningful name for out .csv\n",
    "\n",
    "print(\"We're about to calculate coverage with the following lambdas: \", lambdas)\n",
    "\n",
    "coverage_multiple_lambdas(lambdas, delta, locations, grid_dists, prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:skmob]",
   "language": "python",
   "name": "skmob"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
